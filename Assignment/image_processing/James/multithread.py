import cv2
import numpy as np
import sys
import robomaster
from robomaster import robot
import time
from scipy.spatial import distance as dist
from collections import OrderedDict
import threading # ‡πÄ‡∏û‡∏¥‡πà‡∏° Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Multi-thread

# ======================================================================
# ‡∏Ñ‡∏•‡∏≤‡∏™ ObjectTracker (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)
# ======================================================================
class ObjectTracker:
    def __init__(self, template_paths, max_disappeared=30):
        print("üñºÔ∏è  Loading and processing template images...")
        self.templates = self._load_templates(template_paths)
        if not self.templates:
            sys.exit("‚ùå Could not load template files.")
        print("‚úÖ Templates loaded successfully.")
        self.next_object_id = 0
        self.objects = OrderedDict()
        self.disappeared = OrderedDict()
        self.max_disappeared = max_disappeared

    def _load_templates(self, template_paths):
        processed_templates = {}
        for shape_name, path in template_paths.items():
            template_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
            if template_img is None: continue
            blurred = cv2.GaussianBlur(template_img, (5, 5), 0)
            _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY_INV)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                processed_templates[shape_name] = max(contours, key=cv2.contourArea)
        return processed_templates

    def _get_raw_detections(self, frame):
        blurred_frame = cv2.GaussianBlur(frame, (7, 7), 0)
        hsv = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        v_eq = clahe.apply(v)
        normalized_hsv = cv2.merge([h, s, v_eq])

        color_ranges = {
            'Red': [(np.array([0, 120, 70]), np.array([10, 255, 255])), (np.array([170, 120, 70]), np.array([180, 255, 255]))],
            'Yellow': [(np.array([20, 100, 100]), np.array([30, 255, 255]))],
            'Green': [(np.array([35, 60, 30]), np.array([85, 255, 120]))],
            'Blue': [(np.array([90, 60, 30]), np.array([130, 255, 255]))]
        }
        
        masks = {}
        for color_name, ranges in color_ranges.items():
            mask_parts = [cv2.inRange(normalized_hsv, lower, upper) for lower, upper in ranges]
            masks[color_name] = cv2.bitwise_or(mask_parts[0], mask_parts[1]) if len(mask_parts) > 1 else mask_parts[0]

        combined_mask = cv2.bitwise_or(masks['Red'], cv2.bitwise_or(masks['Yellow'], cv2.bitwise_or(masks['Green'], masks['Blue'])))
        kernel = np.ones((5, 5), np.uint8)
        cleaned_mask = cv2.morphologyEx(cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=1), cv2.MORPH_CLOSE, kernel, iterations=2)
        
        contours, _ = cv2.findContours(cleaned_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        raw_detections = []
        for cnt in contours:
            if cv2.contourArea(cnt) < 1500: continue
            shape = "Unknown"
            best_match_score, initial_shape = float('inf'), "Unknown"
            for shape_name, template_cnt in self.templates.items():
                score = cv2.matchShapes(cnt, template_cnt, cv2.CONTOURS_MATCH_I1, 0.0)
                if score < best_match_score: best_match_score, initial_shape = score, shape_name
            peri = cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, 0.03 * peri, True)
            if len(approx) == 4:
                _, (w, h), _ = cv2.minAreaRect(cnt)
                aspect_ratio = max(w, h) / min(w, h) if min(w,h) > 0 else 0
                shape = "Square" if 0.95 <= aspect_ratio <= 1.15 else ("Rectangle_H" if w < h else "Rectangle_V")
            elif best_match_score < 0.56: shape = initial_shape
            if shape != "Unknown":
                contour_mask = np.zeros(frame.shape[:2], dtype="uint8")
                cv2.drawContours(contour_mask, [cnt], -1, 255, -1)
                max_mean, found_color = 0, "Unknown"
                for color_name, mask in masks.items():
                    mean_val = cv2.mean(mask, mask=contour_mask)[0]
                    if mean_val > max_mean: max_mean, found_color = mean_val, color_name
                if max_mean > 25:
                    raw_detections.append({'contour': cnt, 'shape': shape, 'color': found_color})
        return raw_detections
    
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô update ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ tracking (‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏Ñ‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ)
    def update(self, frame):
        # ... ‡πÇ‡∏Ñ‡πâ‡∏î update ‡πÄ‡∏î‡∏¥‡∏° ...
        # ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å _get_raw_detections ‡∏ï‡∏£‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢
        return self._get_raw_detections(frame)


# ======================================================================
# ‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏´‡∏°‡πà: VideoStream ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Thread-1 (‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á)
# ======================================================================
class VideoStream:
    def __init__(self, camera):
        self.camera = camera
        self.frame = None
        self.stopped = False
        self.lock = threading.Lock()

    def start(self):
        # ‡πÄ‡∏£‡∏¥‡πà‡∏° Thread ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô self.update
        print("‚ñ∂Ô∏è Starting video stream thread...")
        t = threading.Thread(target=self.update, args=())
        t.daemon = True # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Thread ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏¥‡∏î
        t.start()
        return self

    def update(self):
        # ‡∏•‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô background
        while not self.stopped:
            try:
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
                frame = self.camera.read_cv2_image(timeout=2)
                with self.lock:
                    self.frame = frame
            except Exception as e:
                print(f"Error reading frame from camera: {e}")
                time.sleep(0.5)

    def read(self):
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ Thread ‡∏≠‡∏∑‡πà‡∏ô‡∏°‡∏≤‡∏î‡∏∂‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏õ‡πÉ‡∏ä‡πâ
        with self.lock:
            frame = self.frame
        return frame

    def stop(self):
        # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ Thread ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        self.stopped = True

# ======================================================================
# ‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏´‡∏°‡πà: FrameProcessor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Thread-2 (‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û)
# ======================================================================
class FrameProcessor:
    def __init__(self, video_stream, tracker, target_shape, target_color):
        self.video_stream = video_stream
        self.tracker = tracker
        self.target_shape = target_shape
        self.target_color = target_color
        self.processed_frame = None
        self.stopped = False
        self.lock = threading.Lock()

    def start(self):
        print("‚ñ∂Ô∏è Starting frame processor thread...")
        t = threading.Thread(target=self.process_loop, args=())
        t.daemon = True
        t.start()
        return self

    def process_loop(self):
        while not self.stopped:
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å VideoStream
            frame = self.video_stream.read()
            if frame is None:
                time.sleep(0.01) # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ü‡∏£‡∏°
                continue
            
            output_frame = frame.copy()
            
            # --- ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°) ---
            detected_objects = self.tracker.update(frame)

            for obj in detected_objects:
                is_target = (obj["shape"] == self.target_shape and obj["color"] == self.target_color)
                
                x, y, w, h = cv2.boundingRect(obj["contour"])
                box_color = (0, 0, 255) if is_target else (0, 255, 0)
                thickness = 4 if is_target else 2
                
                cv2.rectangle(output_frame, (x, y), (x + w, y + h), box_color, thickness)
                
                label = f"{obj['shape']}, {obj['color']}"
                if is_target:
                    label = "!!! TARGET FOUND !!!"
                    cv2.putText(output_frame, label, (x, y - 15), cv2.FONT_HERSHEY_TRIPLEX, 0.7, box_color, 2)
                else:
                    cv2.putText(output_frame, label, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            # --- ‡∏à‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ---

            # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
            with self.lock:
                self.processed_frame = output_frame

    def read_processed(self):
        # ‡πÉ‡∏´‡πâ Main Thread ‡∏°‡∏≤‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡πÅ‡∏™‡∏î‡∏á
        with self.lock:
            frame = self.processed_frame
        return frame

    def stop(self):
        self.stopped = True

# ======================================================================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö Input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
# ======================================================================
def get_target_choice():
    VALID_SHAPES = ["Circle", "Square", "Rectangle_H", "Rectangle_V"]
    VALID_COLORS = ["Red", "Yellow", "Green", "Blue"]
    print("\n--- üéØ Define Target Characteristics ---")
    while True:
        shape = input(f"Select Shape ({'/'.join(VALID_SHAPES)}): ").strip().title()
        if shape in VALID_SHAPES: break
        print("‚ö†Ô∏è Invalid shape, please try again.")
    while True:
        color = input(f"Select Color ({'/'.join(VALID_COLORS)}): ").strip().title()
        if color in VALID_COLORS: break
        print("‚ö†Ô∏è Invalid color, please try again.")
    print(f"‚úÖ Target defined: {color} {shape}. Starting real-time detection!")
    return shape, color

# ======================================================================
# Main (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ Multi-thread)
# ======================================================================
if __name__ == '__main__':
    try:
        import scipy
    except ImportError:
        print("Installing required library: scipy")
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "scipy"])
        print("Installation successful!")

    target_shape, target_color = get_target_choice()
    
    template_files = {
        "Circle": "./Assignment/image_processing/template/circle1.png",
        "Square": "./Assignment/image_processing/template/square.png",
        "Rectangle_H": "./Assignment/image_processing/template/rec_h.png",
        "Rectangle_V": "./Assignment/image_processing/template/rec_v.png",
    }
    tracker = ObjectTracker(template_paths=template_files)

    ep_robot = robot.Robot()
    vs = None
    fp = None
    
    try:
        print("\nü§ñ Connecting to Robomaster robot...")
        ep_robot.initialize(conn_type="ap") 
        print("‚úÖ Connection successful!")

        print("\nüì∑ Starting camera...")
        ep_robot.camera.start_video_stream(display=False, resolution="720p")
        time.sleep(1) # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ô‡∏¥‡πà‡∏á‡πÜ

        # 1. ‡πÄ‡∏£‡∏¥‡πà‡∏° Thread-1: VideoStream
        vs = VideoStream(ep_robot.camera).start()
        
        # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏° Thread-2: FrameProcessor
        fp = FrameProcessor(vs, tracker, target_shape, target_color).start()
        
        print("‚úÖ All threads are running. Displaying processed feed.")
        print("   Press 'q' on the video window to exit.")

        # 3. Main Thread ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Ñ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        while True:
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á
            processed_frame = fp.read_processed()

            if processed_frame is not None:
                cv2.imshow('Robomaster Camera Feed - Press "q" to exit', processed_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            
            # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ CPU ‡∏Ç‡∏≠‡∏á Main Thread
            time.sleep(0.01)

    except Exception as e:
        print(f"‚ùå A critical error occurred: {e}")
        
    finally:
        print("\nüîå Shutting down all threads and connections...")
        if fp:
            fp.stop() # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ Thread-2 ‡∏´‡∏¢‡∏∏‡∏î
        if vs:
            vs.stop() # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ Thread-1 ‡∏´‡∏¢‡∏∏‡∏î
        
        time.sleep(1) # ‡∏£‡∏≠‡πÉ‡∏´‡πâ Thread ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢
        
        try:
            ep_robot.camera.stop_video_stream()
            ep_robot.close()
        except Exception:
            pass
        cv2.destroyAllWindows()
        print("‚úÖ Shutdown complete.")